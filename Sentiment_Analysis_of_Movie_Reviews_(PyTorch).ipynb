{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis of Movie Reviews (PyTorch).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVA6KaIcDyec+Dy91ev26e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharmin-Shah/Sentiment-Analysis-Pytorch/blob/main/Sentiment_Analysis_of_Movie_Reviews_(PyTorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvMTbKg_n5gx"
      },
      "source": [
        "# **Sentiment Analysis of IMDB Movie Reviews**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_h9L_0koGIS"
      },
      "source": [
        "## <b>Introduction </b>\n",
        "\n",
        "In this project, we are going to train Recurrent Neural Network to hekp us predict the sentiment of a movie review. As this is a basic example, we are going to classify the sentiment into two classes: Positve and Negative.<br>\n",
        "<br>\n",
        "We would also be performing other text preprocessing tasks so we can send only the required data to our model.<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOHF-KC1pQ6R"
      },
      "source": [
        "> Let's start with the imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSJzIiPbnuUv"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle as pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G61_C1M-FAa5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMuO9Ivrpeb7"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxex5_4UplE5"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i74bTV5ZpnJN"
      },
      "source": [
        "import torch\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ajLO0-cqKRY"
      },
      "source": [
        "## Fetching the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1snhHjMqNux"
      },
      "source": [
        "> We will be using the following data for our sentiment analsysis <a href=\"http://ai.stanford.edu/~amaas/data/sentiment/\"> Large IMDB Dataset </a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyvAVOPQqMqt"
      },
      "source": [
        "def get_data():\n",
        "  '''\n",
        "  This function will fetch the data and unzip it for use.\n",
        "  '''\n",
        "  try:\n",
        "    # Download the data using wget linux command\n",
        "    os.system(\"wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\")\n",
        "\n",
        "    # Unzip the tar file to a data folder\n",
        "    os.system(\"mkdir data\")\n",
        "    os.system(\"tar -zxf aclImdb_v1.tar.gz -C data\")\n",
        "    os.system(\"rm -f aclImdb_v1.tar.gz\")\n",
        "  except:\n",
        "    print(\"There was some error while downloading and unzipping the tar file.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4ZWTaC7q1w1"
      },
      "source": [
        "get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5EaENvSs9lw"
      },
      "source": [
        "## Processing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUPtPXc-vgeN"
      },
      "source": [
        "> We will start by creating directories required for the processed files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNDZNQeOsALX"
      },
      "source": [
        "data_dir = \"/content/data/\"\n",
        "\n",
        "# Location of the cache file\n",
        "cache_dir = \"/content/data/sentiment_analysis\"  # where to store cache files\n",
        "# Creating the directory for the same\n",
        "if not os.path.exists(cache_dir): # Make sure that the folder exists\n",
        "    os.makedirs(cache_dir)\n",
        "\n",
        "os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
        "\n",
        "# Create a folder to store the dictionary\n",
        "  \n",
        "word_dir = '/content/data/word' # The folder we will use for storing data\n",
        "if not os.path.exists(word_dir): # Make sure that the folder exists\n",
        "  os.makedirs(word_dir)\n",
        "os.makedirs(word_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1XKRqyGt3Gq"
      },
      "source": [
        "### Loading the data\n",
        "\n",
        "> As are data is present in a text file, we need to read the data and load it in respective dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5HlQEjxrkKu"
      },
      "source": [
        "def read_imdb_data(data_dir='/content/data/aclImdb'):\n",
        "  '''\n",
        "  This function will load the data from text files into the intended directory.\n",
        "  The total reviews are 50k, split as 25k each for train and test. Furthermore,\n",
        "  the total reviews are split into 25k positive and 25k negative. The function\n",
        "  will create respective directories and load the reviews accordingly.\n",
        "  '''\n",
        "\n",
        "  #Define the dictionaries\n",
        "  data = {}\n",
        "  labels = {}\n",
        "    \n",
        "  # First looping through train, test directory  \n",
        "  for data_type in ['train', 'test']:\n",
        "    # Nesting dictionaries\n",
        "    data[data_type] = {}\n",
        "    labels[data_type] = {}\n",
        "    \n",
        "    #Second looping through postive and negative directory\n",
        "    for sentiment in ['pos', 'neg']:\n",
        "        # Nesting dictionaries\n",
        "        data[data_type][sentiment] = []\n",
        "        labels[data_type][sentiment] = []\n",
        "        \n",
        "        #Generate the path for files\n",
        "        path = os.path.join(data_dir, data_type, sentiment, '*.txt')\n",
        "        # Fetch the files\n",
        "        files = glob.glob(path)\n",
        "        \n",
        "        # Third looping through each review file\n",
        "        for f in files:\n",
        "            with open(f) as review:\n",
        "                # Add the review text into the dictionary as a list\n",
        "                data[data_type][sentiment].append(review.read())\n",
        "                # Here we represent a positive review by '1' and a negative review by '0'\n",
        "                labels[data_type][sentiment].append(1 if sentiment == 'pos' else 0)\n",
        "\n",
        "        # Checking for any data mismatch        \n",
        "        assert len(data[data_type][sentiment]) == len(labels[data_type][sentiment]), \\\n",
        "                \"{}/{} data size does not match labels size\".format(data_type, sentiment)\n",
        "            \n",
        "  return data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjYb_ck4xLov",
        "outputId": "6f0fa176-a871-44ac-9f3d-4268ed80ce29"
      },
      "source": [
        "data, labels = read_imdb_data()\n",
        "print(\"IMDB reviews: train = {} pos / {} neg, test = {} pos / {} neg\".format(\n",
        "            len(data['train']['pos']), len(data['train']['neg']),\n",
        "            len(data['test']['pos']), len(data['test']['neg'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IMDB reviews: train = 12500 pos / 12500 neg, test = 12500 pos / 12500 neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h_jgNjrxqjj"
      },
      "source": [
        "### Splitting the data into Train and Test\n",
        "\n",
        "> We will now spilt our data into train and test datasets and perform some shuffling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSDro2bkxhzk"
      },
      "source": [
        "def prepare_imdb_data(data, labels):\n",
        "    '''\n",
        "    Prepare training and test sets from IMDb movie reviews.\n",
        "    '''\n",
        "    \n",
        "    #Combine positive and negative reviews and labels\n",
        "    \n",
        "    #Train Dataset\n",
        "    data_train = data['train']['pos'] + data['train']['neg']\n",
        "    labels_train = labels['train']['pos'] + labels['train']['neg']\n",
        "    \n",
        "    #Test Dataset\n",
        "    data_test = data['test']['pos'] + data['test']['neg']\n",
        "    labels_test = labels['test']['pos'] + labels['test']['neg']\n",
        "    \n",
        "    #Shuffle reviews and corresponding labels within training and test sets\n",
        "    data_train, labels_train = shuffle(data_train, labels_train)\n",
        "    data_test, labels_test = shuffle(data_test, labels_test)\n",
        "    \n",
        "    # Return a unified training data, test data, training labels, test labets\n",
        "    return data_train, data_test, labels_train, labels_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRssjUc6yRTR",
        "outputId": "837503b9-11d5-4940-8120-76800d948275"
      },
      "source": [
        "train_X, test_X, train_y, test_y = prepare_imdb_data(data, labels)\n",
        "print(\"IMDb reviews (combined): train = {}, test = {}\".format(len(train_X), len(test_X)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IMDb reviews (combined): train = 25000, test = 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb2gyxbzyTld",
        "outputId": "5420776e-c9ab-4cd8-ec2b-62e44b14beb6"
      },
      "source": [
        "# Basic check for a train dataset review\n",
        "print(train_X[100])\n",
        "print(train_y[100])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "As has been noted, this formula has been filmed several times, most recently as \"You've Got Mail\", with Tom Hanks and Meg\"Trout Pout\" Ryan. Of the several versions, this is my least favorite. The problem i think is that the studio coasted on the Stars charisma, which doesn't quite cut it here.<br /><br />The chemistry betwixt the two leads never comes to a boil in this movie. There are no real sparks. Van Johnson and Judy Garland remind me of day old donuts, pleasant but bland. And when the leads are boring the rest of the movie can only follow. Judy in particular is disappointing. She looks like she has no neck! I don't know if she was having trouble with pain or something but she looks like a turtle trying to pull it's head into it's shell, all hunched up and everything. I couldn't figure out what Van Johnson was getting so hot about. I would have made a bee line for that cute violin player. And Van wasn't great either. I've always thought of him as a rather generic Hollywood leading man and he doesn't do anything to dispel that image here.<br /><br />If you're a fan of the stars or the early 1900's then you might like this movie. But there are a lot more entertaining romantic comedies out there, and they offer you much more than a mouthful of stale confection.\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocsuFoSJzUOe"
      },
      "source": [
        "### Text Preprocessing\n",
        "\n",
        "> We will now perform the text preprocessing steps:\n",
        "<ul>\n",
        "  <li>Removal of HTML tags</li>\n",
        "  <li>Removal of unnecessary characters</li>\n",
        "  <li>Conversion to lowercase</li>\n",
        "  <li>Removal of stopwords</li>\n",
        "  <li>Stemming (converting verbs,etc to their root form. e.g drinking -> drink)</li>\n",
        "  <li>Generating the wordlist (storing the relevant words in a list)</li>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc0teSXbykN8"
      },
      "source": [
        "def review_to_words(review):\n",
        "  '''\n",
        "  This function will take each review and perform the text pre-processing steps\n",
        "  '''\n",
        "\n",
        "  # Fetching the stopwords list for english language from nltk library\n",
        "  nltk.download(\"stopwords\", quiet=True)\n",
        "  \n",
        "  # Initializing the Stemmer we want to use for our stemming process\n",
        "  stemmer = PorterStemmer()\n",
        "  \n",
        "  # Removing the HTML tags using BeautifulSoup library\n",
        "  text = BeautifulSoup(review, \"html.parser\").get_text()\n",
        "\n",
        "  # Removing any unnecessary characters and converting the text to lowercase\n",
        "  text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
        "\n",
        "  # Creating a list of words by spliting the string\n",
        "  words = text.split()\n",
        "\n",
        "  # Removing the stopwords fromt the list\n",
        "  words = [w for w in words if w not in stopwords.words(\"english\")]\n",
        "\n",
        "  # Performing stemming on the words remaining in the list\n",
        "  words = [PorterStemmer().stem(w) for w in words] # stem\n",
        "  \n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4icp0FVq1vu8",
        "outputId": "95e013a3-16ff-407c-b48a-1e771fd73490"
      },
      "source": [
        "print(train_X[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "As has been noted, this formula has been filmed several times, most recently as \"You've Got Mail\", with Tom Hanks and Meg\"Trout Pout\" Ryan. Of the several versions, this is my least favorite. The problem i think is that the studio coasted on the Stars charisma, which doesn't quite cut it here.<br /><br />The chemistry betwixt the two leads never comes to a boil in this movie. There are no real sparks. Van Johnson and Judy Garland remind me of day old donuts, pleasant but bland. And when the leads are boring the rest of the movie can only follow. Judy in particular is disappointing. She looks like she has no neck! I don't know if she was having trouble with pain or something but she looks like a turtle trying to pull it's head into it's shell, all hunched up and everything. I couldn't figure out what Van Johnson was getting so hot about. I would have made a bee line for that cute violin player. And Van wasn't great either. I've always thought of him as a rather generic Hollywood leading man and he doesn't do anything to dispel that image here.<br /><br />If you're a fan of the stars or the early 1900's then you might like this movie. But there are a lot more entertaining romantic comedies out there, and they offer you much more than a mouthful of stale confection.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftap_9BE1zBD",
        "outputId": "472da736-7046-40c3-fdd1-a37b6bf4b369"
      },
      "source": [
        "review_to_words(train_X[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['note',\n",
              " 'formula',\n",
              " 'film',\n",
              " 'sever',\n",
              " 'time',\n",
              " 'recent',\n",
              " 'got',\n",
              " 'mail',\n",
              " 'tom',\n",
              " 'hank',\n",
              " 'meg',\n",
              " 'trout',\n",
              " 'pout',\n",
              " 'ryan',\n",
              " 'sever',\n",
              " 'version',\n",
              " 'least',\n",
              " 'favorit',\n",
              " 'problem',\n",
              " 'think',\n",
              " 'studio',\n",
              " 'coast',\n",
              " 'star',\n",
              " 'charisma',\n",
              " 'quit',\n",
              " 'cut',\n",
              " 'chemistri',\n",
              " 'betwixt',\n",
              " 'two',\n",
              " 'lead',\n",
              " 'never',\n",
              " 'come',\n",
              " 'boil',\n",
              " 'movi',\n",
              " 'real',\n",
              " 'spark',\n",
              " 'van',\n",
              " 'johnson',\n",
              " 'judi',\n",
              " 'garland',\n",
              " 'remind',\n",
              " 'day',\n",
              " 'old',\n",
              " 'donut',\n",
              " 'pleasant',\n",
              " 'bland',\n",
              " 'lead',\n",
              " 'bore',\n",
              " 'rest',\n",
              " 'movi',\n",
              " 'follow',\n",
              " 'judi',\n",
              " 'particular',\n",
              " 'disappoint',\n",
              " 'look',\n",
              " 'like',\n",
              " 'neck',\n",
              " 'know',\n",
              " 'troubl',\n",
              " 'pain',\n",
              " 'someth',\n",
              " 'look',\n",
              " 'like',\n",
              " 'turtl',\n",
              " 'tri',\n",
              " 'pull',\n",
              " 'head',\n",
              " 'shell',\n",
              " 'hunch',\n",
              " 'everyth',\n",
              " 'figur',\n",
              " 'van',\n",
              " 'johnson',\n",
              " 'get',\n",
              " 'hot',\n",
              " 'would',\n",
              " 'made',\n",
              " 'bee',\n",
              " 'line',\n",
              " 'cute',\n",
              " 'violin',\n",
              " 'player',\n",
              " 'van',\n",
              " 'great',\n",
              " 'either',\n",
              " 'alway',\n",
              " 'thought',\n",
              " 'rather',\n",
              " 'gener',\n",
              " 'hollywood',\n",
              " 'lead',\n",
              " 'man',\n",
              " 'anyth',\n",
              " 'dispel',\n",
              " 'imag',\n",
              " 'fan',\n",
              " 'star',\n",
              " 'earli',\n",
              " '1900',\n",
              " 'might',\n",
              " 'like',\n",
              " 'movi',\n",
              " 'lot',\n",
              " 'entertain',\n",
              " 'romant',\n",
              " 'comedi',\n",
              " 'offer',\n",
              " 'much',\n",
              " 'mouth',\n",
              " 'stale',\n",
              " 'confect']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjxhC7rZ2WCF"
      },
      "source": [
        "### Checkpoint\n",
        "\n",
        "> Whenever we want to perform sentiment analysis, it wouldn't be wise to perform all the steps again and again. So we will create a cache file, that can hold the datasets with their respective pre-processed content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOflG0g811d8"
      },
      "source": [
        "def preprocess_data(data_train, data_test, labels_train, labels_test,\n",
        "                    cache_dir=cache_dir, cache_file=\"preprocessed_data.pkl\"):\n",
        "\n",
        "    '''\n",
        "    Convert each review to words; read from cache if available.\n",
        "    '''\n",
        "\n",
        "    cache_data = None\n",
        "\n",
        "    # If cache_file exists, we will try to read it and load the data\n",
        "    if cache_file is not None:\n",
        "        try:\n",
        "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
        "                cache_data = pickle.load(f)\n",
        "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
        "        except:\n",
        "            pass  # unable to read from cache or cache file not found\n",
        "    \n",
        "    \n",
        "    # If the cache_file doesn't exist, the we write the processed data to the file\n",
        "    if cache_data is None:\n",
        "      # Preprocess training and test data to obtain words for each review\n",
        "      words_train = [review_to_words(review) for review in data_train]\n",
        "      words_test = [review_to_words(review) for review in data_test]\n",
        "      \n",
        "      # Write to cache file for future runs\n",
        "      if cache_file is not None:\n",
        "          # Create a dictionary that contains all the processed data\n",
        "          cache_data = dict(words_train=words_train, words_test=words_test,\n",
        "                            labels_train=labels_train, labels_test=labels_test)\n",
        "          \n",
        "          # Write the dictionary to a pickle file\n",
        "          with open(os.path.join(cache_dir, cache_file), \"wb\") as f:\n",
        "              pickle.dump(cache_data, f)\n",
        "          print(\"Wrote preprocessed data to cache file:\", cache_file)\n",
        "    else:\n",
        "      # Unpack data loaded from cache file\n",
        "      words_train, words_test, labels_train, labels_test = (cache_data['words_train'],\n",
        "              cache_data['words_test'], cache_data['labels_train'], cache_data['labels_test'])\n",
        "    \n",
        "    return words_train, words_test, labels_train, labels_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "740XUtvu5I70",
        "outputId": "00a800c9-09b8-45bd-c39c-e93a255aa18b"
      },
      "source": [
        "# Preprocess data\n",
        "train_X, test_X, train_y, test_y = preprocess_data(train_X, test_X, train_y, test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote preprocessed data to cache file: preprocessed_data.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVMKla4p7N_-"
      },
      "source": [
        "## Building the Vocabulary\n",
        "\n",
        "> We can use the reviews to generate a vocabulary of words. There can be a lot of words, so we need to limit the size of the vocab and keep only the most frequently occuring words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cri7dMXc5bfb"
      },
      "source": [
        "def build_dict(data, vocab_size = 5000):\n",
        "  '''\n",
        "  This function will generate a vocab dictionary. The vocab size can be\n",
        "  provided as an argument, default is 5000 words. The dictionary will be\n",
        "  sorted to in ascending order with the most frequently appering words.\n",
        "  We will also leave 2 spaces at the end of the dictionary, so we can add\n",
        "  'NOWORDS' and 'INFREQ' labels\n",
        "  '''\n",
        "  # A dict storing the words that appear in the reviews along with how often they occur\n",
        "  word_count = {}\n",
        "    \n",
        "  for review in data:\n",
        "      for word in review:\n",
        "          if word in word_count:\n",
        "              word_count[word] += 1\n",
        "          else:\n",
        "              word_count[word] = 1\n",
        "  \n",
        "  # Sorting the dictionary \n",
        "  sorted_words = [item[0] for item in sorted(word_count.items(), key=lambda x: x[1], reverse=True)]\n",
        "\n",
        "  # This is what we are building, a dictionary that translates words into integers\n",
        "  word_dict = {}\n",
        "  for idx, word in enumerate(sorted_words[:vocab_size - 2]): # The -2 is so that we save room for the 'no word'\n",
        "      word_dict[word] = idx + 2                              # 'infrequent' labels\n",
        "      \n",
        "  return word_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3mj4G56H0r2"
      },
      "source": [
        "word_dict = build_dict(train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaxLLno9H8Hn"
      },
      "source": [
        "### Saving the dictionary\n",
        "\n",
        "> We can save the dictionary to a pickle file, so we can use it in futurre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MwuYYevIWse"
      },
      "source": [
        "def save_dict(word_dict):\n",
        "  '''\n",
        "  This function will save the vocab dic to a pickle file\n",
        "  '''\n",
        "  \n",
        "  with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
        "    pickle.dump(word_dict, f)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBnAPvN5KEm4"
      },
      "source": [
        "save_dict(word_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfFEx6qCJwf9"
      },
      "source": [
        "## Transform reviews\n",
        "\n",
        "> We will now perform encoding of the reviews. Using the vocab, we will encode each word to its corresponding integer value. The result will be a matrix of encoded reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRXf6SKoJjfV"
      },
      "source": [
        "def convert_and_pad(word_dict, sentence, pad=500):\n",
        "  '''\n",
        "  This function will perform encoding of each review. We will be using\n",
        "  padding, to make sure that all sentences are of same length. \n",
        "  '''\n",
        "  \n",
        "  # We will use 0 to represent the 'no word' category\n",
        "  NOWORD = 0 \n",
        "  # We use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
        "  INFREQ = 1 \n",
        "\n",
        "  # Creating an empty list for each sentence populated with 0\n",
        "  working_sentence = [NOWORD] * pad\n",
        "\n",
        "  # Enumerate each word in the sentencce and encode it and store it in\n",
        "  # working_sentence variable\n",
        "\n",
        "  for word_index, word in enumerate(sentence[:pad]):\n",
        "      if word in word_dict:\n",
        "          working_sentence[word_index] = word_dict[word]\n",
        "      else:\n",
        "          working_sentence[word_index] = INFREQ\n",
        "\n",
        "  # Return the encoded review and the length of the sentence        \n",
        "  return working_sentence, min(len(sentence), pad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP7BZsUuMPlK"
      },
      "source": [
        "def convert_and_pad_data(word_dict, data, pad=500):\n",
        "  '''\n",
        "  This function will pass each review through the encoder. The result and\n",
        "  the lengths will be returned \n",
        "  '''\n",
        "  result = []\n",
        "  lengths = []\n",
        "  \n",
        "  for sentence in data:\n",
        "      converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
        "      result.append(converted)\n",
        "      lengths.append(leng)\n",
        "      \n",
        "  return np.array(result), np.array(lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nuwp1RjQGtm"
      },
      "source": [
        "train_X, train_X_len = convert_and_pad_data(word_dict, train_X)\n",
        "test_X, test_X_len = convert_and_pad_data(word_dict, test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO8mjZIlQb_U",
        "outputId": "c28ad3ae-5e4f-4f9b-963b-fcbcb93f83b2"
      },
      "source": [
        "# Checking the encoded review and its length\n",
        "print(train_X[100])\n",
        "print(train_X_len[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 539 1376    3  335    6  500  111 3542  712 1907 3970    1    1 2029\n",
            "  335  197  141  395  204   30  809 3881   76 2883   96  374 1084    1\n",
            "   42  177   51   45 3094    2   71 2817 1050 2229 3095    1  620   91\n",
            "   72    1 1954 1491  177  186  302    2  213 3095  765  287   19    5\n",
            " 2529   37  733  483   66   19    5 4972   54  614  253 4219    1  207\n",
            "  461 1050 2229   10  801   15   34    1  117  908    1  931 1050   26\n",
            "  298  131   99  173  258  280  177   55  153    1  654  123   76  346\n",
            "    1  156    5    2   70  164  646  105  517   21 1159 3875    1    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0]\n",
            "111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VypvbO00YVJ5",
        "outputId": "f316aad4-fd8c-4742-9128-a64b90e51b98"
      },
      "source": [
        "train_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGyUOOksQM9V"
      },
      "source": [
        "### Saving the transformed reviews\n",
        "\n",
        "> We will be concatenating the train_y, train_x_len and train_x into a Pandas DataFrame and save it as a csv file  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgcigYG0l5H8"
      },
      "source": [
        "#Creating and saving training dataframe\n",
        "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1) \\\n",
        "        .to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UimBjGEtm88x"
      },
      "source": [
        "## Creating the model\n",
        "\n",
        "> We will now proceed to create our Recurrent Neural Network. For our project, we will be using LSTM layers and Embeddings Layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWeizF7OmEHv"
      },
      "source": [
        "class SentimentAnalysis(nn.Module):\n",
        "  '''\n",
        "  A simple RNN to perform Sentiment Analysis\n",
        "  '''\n",
        "\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "    '''\n",
        "    Initialize the model by setting up the layers.\n",
        "    '''\n",
        "\n",
        "    super(SentimentAnalysis, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_dim,padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "    self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    Perform a forward pass of our model on some input.\n",
        "    '''\n",
        "    x = x.t()\n",
        "    lengths = x[0,:]\n",
        "    reviews = x[1:,:]\n",
        "    embeds = self.embedding(reviews)\n",
        "    lstm_out, _ = self.lstm(embeds)\n",
        "    out = self.dense(lstm_out)\n",
        "    \n",
        "    # Maintaining the output as same as input shape\n",
        "    out = out[lengths - 1, range(len(lengths))]\n",
        "   \n",
        "    return self.sig(out.squeeze())\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK6CHddp0GhL"
      },
      "source": [
        "### Creating Datasets and Dataloaders\n",
        "\n",
        "> Since the data is very very large, we will be using a small subset for this project. But we can use the whole dataset if we have more computing resources."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7kb7h2L4SsP"
      },
      "source": [
        "data_file = os.path.join(data_dir, 'train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoMxrbChzRzn"
      },
      "source": [
        "def create_loader(data_file,batch_size=50):\n",
        "  '''\n",
        "  This function will create loader that can be used to feed the data to the\n",
        "  network.\n",
        "  '''\n",
        "\n",
        "  # Read in only the first 250 rows\n",
        "  train_data = pd.read_csv(data_file, header=None, names=None)\n",
        "\n",
        "  # Turn the input pandas dataframe into tensors\n",
        "  train_y = torch.from_numpy(train_data[[0]].values).float().squeeze()\n",
        "  train_X = torch.from_numpy(train_data.drop([0], axis=1).values).long()\n",
        "  \n",
        "  # Build the dataset\n",
        "  train_ds = torch.utils.data.TensorDataset(train_X, train_y)\n",
        "  # Build the dataloader\n",
        "  train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
        "\n",
        "  return train_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHYDElR4Lmmb"
      },
      "source": [
        "# Creating a train loader\n",
        "train_loader = create_loader(data_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y2u8gzW6CeQ"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "> We will now create a function that can train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_kGe-aE59CN"
      },
      "source": [
        "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
        "  '''\n",
        "  This funcion will take the training parameters and train the model\n",
        "  '''\n",
        "  for epoch in range(1, epochs + 1):\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for batch in train_loader:         \n",
        "          batch_X, batch_y = batch\n",
        "          \n",
        "          # Shifting to GPU is available\n",
        "          batch_X = batch_X.to(device)\n",
        "          batch_y = batch_y.to(device)\n",
        "          \n",
        "          # Optmizing\n",
        "          optimizer.zero_grad()\n",
        "          out = model.forward(batch_X)\n",
        "          loss = loss_fn(out, batch_y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          total_loss += loss.data.item()\n",
        "      print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39XE2h-dsvfw"
      },
      "source": [
        "### Creating the model and training:\n",
        "\n",
        "> We will create the model, define the los function, optimizer and pass the model parameters. We will also transfer the model to GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSrd2aWk7B9j",
        "outputId": "4b595734-9bbd-4c28-c4c9-0983e2c63930"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SentimentAnalysis(100, 256, 5000).to(device)\n",
        "optimizer = optim.Adam(model.parameters(),)\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "train_loader = create_loader(data_file)\n",
        "\n",
        "train(model,train_loader, 15, optimizer, loss_fn, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, BCELoss: 0.5452197691798211\n",
            "Epoch: 2, BCELoss: 0.4080163461863995\n",
            "Epoch: 3, BCELoss: 0.3429047822058201\n",
            "Epoch: 4, BCELoss: 0.2748203212842345\n",
            "Epoch: 5, BCELoss: 0.22618635434657336\n",
            "Epoch: 6, BCELoss: 0.17249603949859738\n",
            "Epoch: 7, BCELoss: 0.13410881471447647\n",
            "Epoch: 8, BCELoss: 0.1164365616682917\n",
            "Epoch: 9, BCELoss: 0.08813222290948033\n",
            "Epoch: 10, BCELoss: 0.060109753909055146\n",
            "Epoch: 11, BCELoss: 0.03992631448199972\n",
            "Epoch: 12, BCELoss: 0.011715514285839163\n",
            "Epoch: 13, BCELoss: 0.004094383300835034\n",
            "Epoch: 14, BCELoss: 0.2840329334288835\n",
            "Epoch: 15, BCELoss: 0.1534613660648465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut9_BttmtZoa"
      },
      "source": [
        "## Testing the Model\n",
        "\n",
        ">We will perform similar tasks like we did for training in terms of data prep."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFc52nH-8e9J"
      },
      "source": [
        "# Creating a test data file\n",
        "pd.concat([pd.DataFrame(test_y), pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1) \\\n",
        "        .to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSo9HMyU98su"
      },
      "source": [
        "test_file = os.path.join(data_dir, 'test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeNpcBiAczOZ"
      },
      "source": [
        "#Creating the test loader\n",
        "test_loader = create_loader(test_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXstoY4L9O4Z"
      },
      "source": [
        "def test_model(model, test_loader, criterion):\n",
        "  \n",
        "  test_losses = [] # track loss\n",
        "  num_correct = 0\n",
        "  \n",
        "  model.eval()\n",
        "  # iterate over test data\n",
        "  for batch in test_loader:\n",
        "\n",
        "    batch_X, batch_y= batch\n",
        "    \n",
        "    batch_X = batch_X.to(device)\n",
        "    batch_y = batch_y.to(device)\n",
        "    \n",
        "    output = model.forward(batch_X)\n",
        "   \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output, batch_y.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output)  # rounds to the nearest integer\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(batch_y.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "  # -- stats! -- ##\n",
        "  # avg test loss\n",
        "  print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "  # accuracy over all test data\n",
        "  test_acc = num_correct/len(test_loader.dataset)\n",
        "  print(\"Test accuracy: {:.3f}\".format(test_acc))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3omnlpCee4RP",
        "outputId": "31900384-957b-4f12-e2f4-c491123dbe1b"
      },
      "source": [
        "test_model(model,test_loader,loss_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.465\n",
            "Test accuracy: 0.846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq95olivuVua"
      },
      "source": [
        "## Prediction on real data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZatJisa9R9-"
      },
      "source": [
        "def predict(review,word_dict,model):\n",
        "  '''\n",
        "  This function will take the review, the word dictionary and the model and\n",
        "  return the predicted sentiment of the review\n",
        "  '''\n",
        "  \n",
        "  # Encode the review and get its length\n",
        "  review_encoded,review_len = convert_and_pad_data(word_dict, review)\n",
        "  \n",
        "  # Append the length to encoded review so it can be provided to the model\n",
        "  review_p = np.append(review_len,review_encoded)\n",
        "\n",
        "  # Convert the array to torch tensor and shift it to gpu if available\n",
        "  review_t = torch.from_numpy(review_p).to(device)\n",
        "\n",
        "  # Pass the tensor to the model and get its output\n",
        "  output = model(review_t.unsqueeze(dim=0))\n",
        "  \n",
        "  print(output)\n",
        "  if torch.round(output) == 1:\n",
        "    return 'positive'\n",
        "  else:\n",
        "    return 'negative'\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-xAEelE49MK"
      },
      "source": [
        "### Providing the url for a movie review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdOqQyMDyMr9"
      },
      "source": [
        "# Get the reviews page\n",
        "page = requests.get('https://www.imdb.com/title/tt0087233/reviews?sort=submissionDate&dir=desc&ratingFilter=0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-0QZEG9yZAo"
      },
      "source": [
        "# Parse the page\n",
        "soup = BeautifulSoup(page.text, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of7eXFBl03Ws"
      },
      "source": [
        "# Navigate and get all the reviews\n",
        "reviews_container = soup.find_all(class_='text show-more__control')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvPVGak_1f-o"
      },
      "source": [
        "# Cleaning the text\n",
        "reviews = []\n",
        "for review in reviews_container:\n",
        "  review_t = review.text.strip()\n",
        "  reviews.append(review_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6DbiCNN1e50",
        "outputId": "6b0d2e6f-3f5a-41e0-abbc-1cce01f9433e"
      },
      "source": [
        "len(reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a1snVIiJn9A",
        "outputId": "618cb1f7-e35a-4ef5-edf7-df4cf4dd3f2c"
      },
      "source": [
        "# Perform the predictions for the reviews\n",
        "\n",
        "for r in reviews:\n",
        "  p = predict([r],word_dict,model)\n",
        "  print(r)\n",
        "  print(\"\\n\")\n",
        "  print(p.upper())\n",
        "  print(\"----------------------------------------\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.4181, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "Though not optimally made, this movie is captivating.It 'only' shows the love affair of two people, alas married, who have no intention to stray. It simply is their inherent desire of just being together that brings them into the state of affairs.Great play and / or maquillage on the side of especially Meryl Streep that convincingly and immediately shows her internal state(s): feeling good, feeling bad, feeling happy, etc.The audience can follow as observer, how these two come together, ever closer.A nice trick to show the true love of the two is by not getting them together for sex during the plot. Alongside the wife of Frank, who immediately states \"It is worse!\" when Frank tells her, that he didn't even sleep with Molly. She seems to feel what is going on.Harmless. The audience is not presented with big drama, no sex, no cruelty. Which renders this movie better. Harmless, because the audience knows almost exactly what goes on. Except of a few things, like the discussions between Brian and Molly about the relationship.'Harmlessness' doesn't have to be a bad attribut; especially in a generation like the current one, where cinema and movies seem to run the better, the more they contain violence, blood, beating, raping.A remarkably intense and recommendable movie. Please, overlook the less than perfect direction, cinematography and story board. Cross the overdrawn first 25 minutes. Good idea, but just too long.Enjoy the rest, instead!\n",
            "\n",
            "\n",
            "NEGATIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9934, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "\"Falling in love\" can (and should in my opinion) be seen as a modernization of \"Brief encounter\" (1945, David Lean). The metro has been substituted for the train and the extramarital relation between Frank Raftis (Robert de Niro) and Molly Gilmore (Meryl Streep) is a little bit less subdued and more explicit than the one between Alec Harvey (Trevor Howard) and Laura Jesson (Cecilia Johnson) in \"Brief encounter\".Did it succeed? I think not, and the fact that a metro station is less photogenic than a train station (the scenes in which Alec and Laura are running through shady station tunnels to catch the last train after a date are mutch more beautiful than the corresponding metro scenes in \"Falling in love\") is but a minor reason.The first major reason in the happy ending. This gives \"Falling in love\" the flavour of \"When Harry met Sally\" (1989, Rob Reiner) without the humor.The second major reason are the defects in the script. These defects are noteworthy because Pulitzer prize winner Michael Cristofer was responsible for this script. The defects are in my eyes most prominent in the first and last meeting of Frank and Molly at booktore Rizzoli. The first meeting is very 1940's romcom cliché. The last meeting is exactly 1 year later (same time, same place), again at the Christmas shopping season. From previous conversations we know that both Frank and Molly are divorced in the last year. Although this definitely eliminates an obstacle for resuming their extramarital relationship, they both refuse to mention this fact in their small talk. In so doing the end becomes more romantic bur far less believable.In summary, \"Falling in love\" is a film with good actors and a bad script, far less convincing than the relationship between de Niro and Streep in \"The Deer hunter\" (1978, Michael Cimino).One last point is the city of New York. In most films from the '70s and early '80s, New York is a city in decay (\"The French connection\", 1971, William Friedkin or \"Manhattan\", 1979, Woody Allen). In \"Falling in love\" however, New York seems to be a pleasant place full of nice restaurants, stores and coffee corners.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.8142, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "Two very one dimensional people decide that they really are in love and abandon their existing lives to eventually get together, presumably destroying their existing spouses lives in the process and we are meant to be sympathetic and say 'ahh what a lovely movie'. I wanted to ask, if you were married before presumably you thought you were in love then so how can you be sure that you are now and that in a year or two you won't find another who is 'the one'.Actually did not think it was that well acted - i'm not saying that De Niro and Streep are not fine actors, they are but not in this film.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9848, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "I really enjoyed this romance, as it reminded me of Brief Encounter many years ago\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9686, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "I came across this film by accident one night. I'd never heard of it but it starred Meryl Streep and Robert De Niro, so I stuck it on. A more modern take on Brief Encounter, this film sings because of the chemistry between its leads and it quickly became clear to me that it'd be a film I'd revisit.Sometimes you've just got to go with a film for what it is - Falling in Love won't change your life and it doesn't push any cinematic boundaries, but it's a classic love story that brought together two of the best actors of its time. It's now one of my (not so) guilty pleasures.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.7663, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "Welcome back to another edition of Adam's Reviews!! **queue in intro music**Tonight's movie review is drama Falling in Love (1984), where you have giant actors, yours truly Robert De Niro and the queen herself Meryl Streep, both greats and both Oscar winners, so you would expect them to deliver an awesome performance. First few minutes of the flick was going good including the train ride into New York and the crazy Christmas shopping scene. But then the movie went flat, just went downhill and awkward as. The story is we have two very different marriages, so a married man and married woman who meet on the train and fall in love. Their marriage lives are slowly falling apart without their partners really understanding what is happening or what they did wrong. There are moments where both the characters realize what they're doing is wrong however due to the supposed chemistry, it leads to both characters to bond and ultimately love each other.I had great expectations, considering these two stars but both play unsympathetic characters and are given poor dialogue to play with. And their partners?? So much potential was there to play around with. And the adulterers themselves? The plot around them catching up is corny and very awkward where it makes you question where the spark is between these two characters. Streep does well to display her moods and quiet analysis of what is happening but man there are so many missed opportunities. I had to watch this movie parts due to how flat it was. The story is dull and the tone of the film is a mess, not sure what was happening. Very disappointing flick, overall 4/10\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.8135, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "Star studded cast and some awesome scenes involving trains\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.8393, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "Two married people meet on a train, develop an innocent friendship, and eventually fall in love. If that premise sounds familiar, it's because Falling in Love is a second remake of 1945's Brief Encounter. I've seen all three, and this version is by far my favorite. The first one was depressing and boring, the second one was an improvement by being merely boring, and this one is neither!Meryl Streep and Robert De Niro are given a bit of a break from their usually heavy fare. This movie certainly has its dramatic moments, but the love story between the leads is very sweet and endearing. They don't jump into an affair, and they don't necessarily seek out companionship because they're unhappy at home. Jane Kaczmarek and David Clennon are their spouses, and while they're not perfect, they do have working marriages and aren't seeking a new life partner. They simply enjoy each other's company. It's pretty rare to actually like someone you're falling in love with, since so many other factors often cloud our judgement; Meryl and Bobby have such a natural, genuine chemistry together and it's easy to root for them.Falling in Love isn't a fluff piece, so don't write this off as a romantic comedy. The leads are committing adultery, so you should expect lots of conflicted feelings, and lots of hurt feelings from the spouses. Also, Meryl's father dies, and she gets a very emotional funeral scene to show off her acting chops. Keep an eye out for Harvey Keitel, George Martin, and Dianne Wiest in the supporting cast. Also keep an eye out for some festive cheer; it might not seem like the best subject matter to include in a Christmas movie, but it gives you a good excuse to rent it in December.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9970, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "This is one of the reasons why more and more American marriages break up, causing the social infrastructure completely cracked beyond repair. When man and woman decided to get married, usually because they love each other so much, the regular dating become so inconveniently to them, they want more from each other, they want to eat together more, they want to sleep and make love every night, they don't want to go back to their own homes or bedrooms alone no more, so they decide to get married.But how long this romantic fire would have enough fuel to keep burning not distinguished? When the crazy passion to each other die down, when you have kid(s) they cried and crapped every night, when you have more endless chores at home to do, the mortgage, the loans, the more and more credit cards debts...The love and the promise that until death that could only separate them apart would just simply fade away. The relation becomes a suffocating bondage, going back home becomes such a bore...Then your eyes and mind are wandering off, looking for new exciting scenes, a handsome dude, a pretty face in the crowd, not only distracting your mind but attracting your soul. If the encountering goes well, the new energized chemistry formula is right, the extinguished fire in your heart, between your legs would be re-ignited and out of control. Morality? Faithfulness? Loyalty? Responsibility? Family value? Everything would be out of the window and could not be care less when an affair just fall upon you like a Newton's Apple, a windfall, you just can hardly wait to take a bite.Yes, why not, ladies and gentlemen, as long as you don't have kids yet, just do it, get a quick divorce, get your new love while you still can, don't let your newly found love get away, get re-married, repeating the \"till death do we depart\" white lie to your newly acquired property until the next or the next, next repeating, same old, same old crap.There are so many movies like this one and, you just love to watch them again and again, because an outside marriage affair is not as dirty or immoral as the word \"adultery\" by those right wing conservative churchgoers' tagged. Go for it, as long as you don't have kids.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.3453, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "I enjoyed it, merry was as usual, the best, it was a new de niro style for me but he was also perfect,\n",
            "\n",
            "\n",
            "NEGATIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.8275, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "The basic virtue is the lovely simplicity. It can be defined as realism. As source of seduction, but the most important thing, in fact, no definition works in this case. Because it is one of films, like a flavour, remaining for long time in memory as precious sign of exceptional discover. A story reduced at its essence. Romance, off course, but, more important, a so familiar drama about a powerfull connection and fundamental choice.Sure, after decades, the second virtue must be recognized as the performances of Meryl Streep and Robert de Niro. Their wise use of silent moments, their gestures and looks and the love story intense in beautiful and profound special sense.A film about two ordinary people and their great connection. Romance, beautiful one, no doubts. But, after the final credits you feel it be more , in the most inspired manner imaginable.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9989, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "I had to watch a 30 year old movie to see majestic acting. Even if they play average pple who could be my neighbour Streep and DeNiro has dignity and such strong auras I want to hear every word they say and I want to see every step their characters do. Because of their wise playing I feel they know something I don't and it makes me be curious of them.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9862, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "Falling in Love is well crafted, well acted, with charisma and chemisty about its two leads. It might be said by critics as trite romantic drama but the two main characters are quite happy and without much conflict in their marriages and this makes a union centre on love rather than betrayal. There are no bad spouses here and no high moral lessons. Awkward, clichéd conversation tends to come about between two middle class strangers who are a man and a woman. Most viewers will give broad harbour to banality if it avoids melodrama, which this does.\n",
            "Americans feel a much larger sense of guilt when it comes to cheating on their partners. 84 percent of Americans then viewed infidelity as morally wrong, while a mere 47 percent of French people surveyed look down on it, according to research in the early 1990s. Falling in Love is not a film reflecting anything, despite the growing trend then of infidelity research. Most experts think it is unlikely that infidelity was more popular in the 1980s than it was in the 1950's and 1960's - it was just that people were thinking more about doing it in the mid 1980s and it was worth tapping into that idea.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9106, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "I never have had a good feeling about Meryl S acting. She always seems to be holding back her feelings and emotions. Her story lines seem to be so bland and boring. Therefore I hate this movie. It lacks any sort of excitement that one would generally find in this sort of story. The lines are ho hum...I do like Roberts wife in this movie. At least she has personality!\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9851, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "If you are into complete 100% realism, then you would have a bone to pick with this film. I mean true love... if you believe in love at first sight; you could probably believe that two strangers chance meeting could be the beginning of something beautiful. Or if hardened by cynicism, you'd probably say, nay it'd never happen it's just boredom in life's routine.Meryl Streep, to me mainly, has done her part on this film. She is not only natural and luminous, but you even don't think that she's acting! She's lived this whole life through! The way she's hesitating whether she should stop the affair with a married man (De Niro) or just let it all be. The way she struggles herself and this new feeling that doesn't allow her to lead her normal life anymore is believable as well. You won't doubt a minute that she's feeling all this. As for De Niro even though he's an actor he always embodies such charisma and sex appeal, he's able to carry himself as such a regular simple man-all that there is to him is that he is in love with a married woman other than his wife.Bottom line: If you appreciate great acting, and are a romantic at heart, you will not be disappointed with this film. Overall rating: 7 out of 10.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9992, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "A wonderful film where Streep and DeNiro meet by accident and when they take each other's gifts in error, the love process starts.Though both are married to lovely people, there has something gone out of each marriage. Each person seems to be living parallel lives with regard to the other.For Streep, the relationship comes at a time of her father's illness and subsequent passing. DeNiro, in construction, has the opportunity to go to Houston.The story is told in plain, simple matter. There are no overt sexual scenes or violence.I questioned the role of Dianne Wiest here. Her character is under-rated and she was virtually mumbling along the way.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9952, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "I loved this movie the first time I saw it. This story proves that fate is the hunter and some things are not written into the script of life until the last minute. Meryl and Robert are perfect in their roles as are Jane, David, Harvey and Diane. The scenes on the streets of New York were pleasant and true. I enjoyed the understated element of suspense also. I always marvel at Meryl's facial expressions, they speak for her. It's a pleasure to see Robert play an ordinary blue-collar worker, he did it well. The music of \"Mountain Dance\" fit the movie perfectly. Well written, excellently acted, always a favorite. I have recommended this movie to many friends.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.6774, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "The storyline is very simple and De Niro and Meryll plays the lead roles. They both lit the screen with so much charm that it would pass for a good movie. The on-screen chemistry between them were so natural. Apart from the lead acting/actors the music of Gruzin was fine.Reviewing the cons, firstly the movie is inspired from \"Brief Encounter\". There is not one comedy or a memorable phrase in the movie and i'm so surprised the massive on-screen talent of De Niro & Streep were wasted. The screenplay was bad,IMO, and for the first time i'm getting bored to see Meryll (in this movie) blushing like a college girl every time she sees De Niro. The cinematography was just okay.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9452, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "I liked this movie very much, and it was especially nice to watch it in Christmas time, as it showed New York in lavish Christmas decorations. Complete with the famous skating rink and all! :-) I also liked that although the ending was very foreseeable, this is Hollywood after all, this was not evident until - well, the ending! This movie is rather like \"Brief Encounter\" from the 1940:s. The same story about two people, already married, meeting by chance at a train/train station, and falling in love against their will. Also: in both movies, the couple get a chance to have sex, but they never do it. By the way, I find the fact that they do NOT have sex much more romantic than if they had. It shows that we have to do with basically decent people caught up in an unhappy situation - and because of this it is easier to sympathize with them.\"Brief encounter\" ended unhappily though. Although the men in both movies got a job far away and moved, to put an end to the hopeless relation-that-must-not-be, in the old movie he never came back and - we must presume - the lovers never met again. I suppose everything else would have been impossible in the 1940:s, but in the 1980:s divorce was not such a bad thing anymore, and the movie-makers could allow the illicit couple to get together in the end.I suppose this kind of story is many bored, married women's fantasy... You are bored with your husband, but there are no \"real\" problems that would make it \"legitimate\" to leave him. Also - where would you go, what would you do..? Maybe you would just turn up lonely, unhappy and poor.Although you are in mature age, you have still not quite forgotten that dream about the prince on the white horse, who are coming to save you... maybe this is still not too late, although you are 35, 40, 45, 50..? But you do not want to go out and look for a new man deliberately, because that would be too cheap and trashy. And you would not want a man who was willing to do that to HIS spouse either - because a man like that would not be worth the degree of love and passion you dream of. Therefore you want it to happen as in these movies (and many more like them): by chance, against your conscious will - so that you can continue to look upon yourself - and him - as the decent people in the movies...\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.8854, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "It has two of the best actors of the last times in their early careers. The script of the drama is fairly simple and since the beginning of the film its end can be predicted without error. Due to the many coincidences that occur throughout the film. I liked the atmosphere of Christmas in NYC, the hectic city life and the usual executive living in the suburbs, keeping a daily routine of travel and adherence to a schedule. For this reason there are many chances to have an opportunity like the one this couple had to develop a love affair Ms. Streep, as always, an excellent actress playing the role of the perfect beautiful medium class wife. For Mr. De Niro, unlike other roles, I do not think he had to work too hard in his role. Entertaining film.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9995, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "Falling in Love can be described as an urban American Brief Encounter. Reteamed for the first time since The Deer Hunter, Robert De Niro and Meryl Streep star as a married couple. Thing of it is, they're not married to each other. Harvey Keitel,Jane Kaczmarek,George Martin,David Clennon and Dianne Wiest co-star to play key supporting roles.The movie is directed by Ulu Grosbard.Two married strangers meet randomly, become friends, and fall in love. They spend time together, riding the train into the city of New York, and begin meeting for coffee or lunch. They enjoy their time together and this enjoyment eventually blossoms into love. While Christmas shopping for their respective families, architect Frank Raftis and graphic artist Molly Gilmore \"meet cute,\" their holiday packages becoming mixed up. What starts as a pleasant chance acquaintance blossoms into romance. Inevitably, however, both parties realize that what they're doing is wrong--a shade too late to save their marriages, as it turns out. The film ends with a bittersweet \"one year later\" coda.This is a delicately crafted and richly acted drama about a form of romantic love characterized by infatuation.Added to that,in a very different role, Robert De Niro is excellent as the leading man and Meryl Streep, as usual, gives a stellar performance.Aside from them, the fine supporting cast bring the story to life with flair and sensitivity.Overall,it is one well-acted movie.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9717, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "'Falling In Love', directed by Ulu Grosbard, is a romantic-drama, that is mature & at times, heartfelt. I also enjoyed the Performances by it's star-cast! 'Falling In Love' tells the story of how Two married strangers meet randomly, become friends, and eventually fall in love.Michael Cristofer's Screenplay is mature & uncomplicated. Sure, this love-story isn't without the obstacles, but I thought the film runs with a simple tone. Though the Screenplay dips in the middle, it's culmination comes across as subdued & polite. Ulu Grosbard's Direction is quite good. Cinematography & Editing are passable.Performance-Wise: I truly believe that 'Falling In Love' is a superior product, also for it's strong performances it has in store. De Niro is superb, once again. He's so restrained & controlled in each and every sequence. It takes my breath away just by thinking, that this is the very same actor who pulled off terrorizing roles in 'Cape Fear' & 'The Godfather Part 2'. What a range and what a worthy performer! Meryl Steep on the other-hand, explores acting like no one manages too. To say, that, Streep is the finest actress of the modern-era, is such an under-statement.On the whole, 'Falling In Love' is definitely worth a watch. It offers a punch!\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.4407, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "If you believe this is wrong, I totally agree with you but DeNiro and Streep will force you in this movie to re-think the whole thing only if the story is like theirs.The movie starts with DeNiro not believing that one of his friends is capable of cheating on his wife and divorcing her to marry someone else! Only to find himself in his friend's shoes later! It's a very simple and honest story about the fact that no matter what you do and how hard you try, you don't control feelings they actually do control you! There are two scenes that will truly make you think and think. The scene when DeNiro tells his wife that he loves someone else and she slaps him on the face. He does nothing for what he can do! Seriously, what can be done?! If your partner comes to tell you that he/she is not in love with you anymore and that he/she is in love with someone else! What can you do? Can you force him/her to love you back?! And the second scene is when Streep drives her car hysterically to catch up with DeNiro (oh my God... just oh my God!) You HAVE TO see it.\n",
            "\n",
            "\n",
            "NEGATIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.5353, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "and i mean that in a good way.for one thing,the story isn't contrived like so many others of the genre.also it's not overly sentimental or sappy.you really believe these two people could fall in love.also the way they fell in love was realistic.Robert De Niro and Meryl Streep really do come across as genuine,playing two lonely people who meet through fate.but there's only one small hitch:they're both married.the movie is not fast paced,so if that's what you're expecting,you'll be disappointed.instead,it's an honest,unconventional love story that takes some time for the relationship to develop between the two central characters.Dianne Wiest has a small role,and is almost unrecognizable.it's nice to see Harvey Kietel in an everyman kind of role,as well as Jane Kaczmarek(Malcolm in the Middle).but it's really Streep and DE Niro who make the movie what it is.if their portrayals were not authentic or honest,the film would not work.for me,Falling in Love is a 7/10\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n",
            "tensor(0.9961, device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "This movie proves it. Stay single, stay honest and have fun! Why jumping into marriage, then get tired, then cheat, then lie, then make excuse, and make everybody's life miserable and complicated? Look at Frank, look at Ed, look at Molly.Just imagine, if you are forced to eat ham and cheese everyday 3 times a day rest of your life, what would you do? You will go eat from the bin! Just imagine, if you are forced to wear the same sweater everyday rest of your life, you will go out of your mind until you are choked and rip it off to shreds! Marriage is a very wrong concept where two partners are tied up and stuck in a situation like this. Resuls in cheating and divorce. That's the reason, most married people crave to cheat their spouse. Affair adds spice to their boring life. But then again, why saying those words in the first place, \"for better or worse, richer and poorer, until death do us apart\", when everybody already knows marriage is obviously NOT going to last for ever. Then why going through this hypocrisy? Can you guaranty that some day you will not meet somebody else who you will find more compatible. Human beings fall for temptations, it's their nature.Maryl Streep manages to irritate me in almost all her movies. Can she say a complete sentence properly? It was like she was forgetting her lines from the script or didn't read her lines or something! And what's with the over-sized dresses and jackets, like 5 size larger than her actual size? Frank's wife is lovely, but Molly's husband looks like a homeless bum. Molly deserved better. On the other hand, what did Frank lack in his married life? Somebody please tell me that. So he cheated just for fun? for a change? This movie makes us ponder about hypocrisy, honesty, faith and temptations.\n",
            "\n",
            "\n",
            "POSITIVE\n",
            "----------------------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxyOt95e6Ymc"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "> We can observe, that some of the reviews may be misclassified due to the absence of words that make up the vocabulary. As we train more, and tune the hyper paramters, we can achive much better accuracy ahead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpeM-_d95a1O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}